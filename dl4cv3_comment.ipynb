{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation\n",
    "\n",
    "     colab -> 런타임 -> 런타임 유형 변경 -> GPU -> 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import matplotlib.pyplot as plt\n",
    "import torchsummary\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# dummy class\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "class Densenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Densenet, self).__init__()\n",
    "\n",
    "def print_acc_class(net, partition):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'],\n",
    "                                         batch_size=args.test_batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "    net.eval()\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "def plot_loss_variation(result, **kwargs):\n",
    "    list_data = []\n",
    "    for epoch, train_loss in enumerate(result['train_losses']):\n",
    "        list_data.append({'type': 'train', 'loss': train_loss, 'epoch': epoch})\n",
    "    for epoch, val_loss in enumerate(result['val_losses']):\n",
    "        list_data.append({'type': 'val', 'loss': val_loss, 'epoch': epoch})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train loss vs Val loss')\n",
    "    plt.subplots_adjust(top=0.89)\n",
    "\n",
    "\n",
    "def plot_acc_variation(result, **kwargs):\n",
    "    list_data = []\n",
    "    for epoch, train_acc in enumerate(result['train_accs']):\n",
    "        list_data.append({'type': 'train', 'Acc': train_acc, 'test_acc': result['test_acc'], 'epoch': epoch})\n",
    "    for epoch, val_acc in enumerate(result['val_accs']):\n",
    "        list_data.append({'type': 'val', 'Acc': val_acc, 'test_acc': result['test_acc'], 'epoch': epoch})\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'Acc', marker='.')\n",
    "\n",
    "    def show_acc(x, y, metric, **kwargs):\n",
    "        plt.scatter(x, y, alpha=0.3, s=1)\n",
    "        metric = \"Test Acc: {:1.3f}\".format(list(metric.values)[0])\n",
    "        plt.text(0.05, 0.95, metric, horizontalalignment='left', verticalalignment='center',\n",
    "                 transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n",
    "\n",
    "    g = g.map(show_acc, 'epoch', 'Acc', 'test_acc')\n",
    "\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train Accuracy vs Val Accuracy')\n",
    "    plt.subplots_adjust(top=0.89)\n",
    "\n",
    "def train(net, partition, optimizer, criterion, args):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'],\n",
    "                                              batch_size=args.train_batch_size,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc\n",
    "\n",
    "\n",
    "def validate(net, partition, criterion, args):\n",
    "    valloader = torch.utils.data.DataLoader(partition['val'],\n",
    "                                            batch_size=args.test_batch_size,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def test(net, partition, args):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'],\n",
    "                                             batch_size=args.test_batch_size,\n",
    "                                             shuffle=False, num_workers=0)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "    if args.model == 'CNN':\n",
    "        net = CNN()\n",
    "    elif args.model == 'Resnet':\n",
    "        net = Resnet()\n",
    "    elif args.model == 'SE_Resnet':\n",
    "        net = SE_Resnet()\n",
    "    elif args.model == 'Densenet':\n",
    "        net = Densenet()\n",
    "    else:\n",
    "        raise ValueError('In-valid model choice')\n",
    "    net.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        ts = time.time()\n",
    "        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args)\n",
    "        val_loss, val_acc = validate(net, partition, criterion, args)\n",
    "        te = time.time()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(\n",
    "            'Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch,\n",
    "                                                                                                                  train_acc,\n",
    "                                                                                                                  val_acc,\n",
    "                                                                                                                  train_loss,\n",
    "                                                                                                                  val_loss,\n",
    "                                                                                                                  te - ts))\n",
    "\n",
    "    test_acc = test(net, partition, args)\n",
    "    print_acc_class(net, partition)\n",
    "\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['train_accs'] = train_accs\n",
    "    result['val_accs'] = val_accs\n",
    "    result['train_acc'] = train_acc\n",
    "    result['val_acc'] = val_acc\n",
    "    result['test_acc'] = test_acc\n",
    "    return vars(args), result\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "print('ready.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Going deeper: Case studies\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide74.PNG?raw=true)\n",
    "\n",
    "    ImageNet 데이터 베이스를 이용해서 1000개의 클래스에 분류 대한 top-5 error 그래프입니다.\n",
    "    cifar dataset에 비해서 입력 이미지도 크고(227x227x3)\n",
    "    분류해야 할 클래스도 많기 때문에 어렵겠죠? 데이터셋도 더 크구요.\n",
    "    이 network들이 에러를 줄이기 위해 어떠한 테크닉을 사용하였는지, case study를 통해 같이 살펴보겠습니다.\n",
    "***\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.1 AlexNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide71.PNG?raw=true)\n",
    "\n",
    "    CNN을 사용해서 Imagenet Challange에서 우승한 최초의 딥러닝 네트워크인 alexnet입니다.\n",
    "    논문에도 아키텍쳐 다이어그램이 위에 짤린것으로 나타내는데,\n",
    "    정확히는 모르겠지만 위 아래가 동일한 구조이기 때문에 의도적으로 한 것 같습니다.\n",
    "\n",
    "    이 아키텍처 다이어그램이 복잡해보이는 이유는\n",
    "    2012년에는 그래픽카드 메모리가 크지 않았기 때문에\n",
    "    2gpu를 사용해서 큰 모델을 학습시키기 위해서, two-stream network 디자인 했습니다.\n",
    "    그 당싱 학습하는데 6일이 걸렸구요, 지금은 몇분 만에 학습이 가능 합니다.\n",
    "\n",
    "    alexnet의 특징은 처음으로 CNN을 제대로 사용할 수 있다고 말씀드릴 수 있겠는데요,\n",
    "    첫번째는 vanishing gradient 문제를 해결하기위해 ReLU를 사용했으며,\n",
    "    overfitting을 피하기 위해 dropout, weight decay를 사용했습니다.\n",
    "    weight decay는 특정한 weight값이 너무 크면 큰 만큼 값을 줄여줘서(부식시킨다) regularization해주는 겁니다.\n",
    "    (신경망이 범용성을 갖도록 처리하는 거니까 regularization은 일반화 정도라고 생각하시면됩니다 normalization, 정규화와는 다른의미입니다.)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.1 AlexNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide72.PNG?raw=true)\n",
    "\n",
    "    alexnet을 단순화 시켜보면 이렇습니다. input을 conv, non-linaer, pooing 반복반복,\n",
    "    마지막에 fcfcfc, lenet, cnn의 기본구조와는 거의 차이가없죠?\n",
    "    그래서 이 친구 같은 경우는 아직 advanced cnn은 아니다.\n",
    "    뭐 처음으로 convolution layer를 dnn에 잘 적용했기때문에 상징적으로 다뤄보았구요,\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/Lec6-A.pdf_page_17.png?raw=true)\n",
    "\n",
    "    이제부터 advanced cnn을 살펴보겠습니다.\n",
    "    VGGNet은 2014년도에 2위를 한 oxford대학의 네트워크입니다. 1위는 GoogLeNet이 했죠.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide75.PNG?raw=true)\n",
    "\n",
    "    이 네트워크를 다루는 이유는 VGGNet의 네트워크 디자인 룰이 간단하고 효과적이기 때문에\n",
    "    아직까지도 많은 영향을 미치고 있기 때문입니다.\n",
    "    네트워크를 간단히 살펴보자면, conv,conv,pooling -> .... -> conv,conv,conv,conv,poopling,fcfcfc 구조네요.\n",
    "    conv를 연속적으로 한다는 것 빼고는 딱히 alexnet과 큰 차이는 없지만,\n",
    "    우리는 Design rule을 볼 필요가 있습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_041.png?raw=true)\n",
    "\n",
    "    첫번째 디자인 룰은 same convolution을 합니다.\n",
    "    위에서 한번 말씀드렸듯이 padding 1을 추가해서 feature map이 작아지는 것을\n",
    "    방지하여 좀 더 깊은 네트워크를 만들 수 있게 합니다.\n",
    "\n",
    "    그리고 conv과 pooling을 하는 이전과는 다르게 conv을 몇번하고 pooling을 하는\n",
    "    구조를 보실 수 있으실텐데요,\n",
    "    우리는 이미지에서 가로세로 5칸의 window를 featuremap에 담고싶다고 하면,\n",
    "    (이 윈도우를 receptive field라 위에서 말씀드렸죠?) 5x5 kernel에서 conv를 한번 하는것보다,\n",
    "    3x3 kernel을 이용하여 conv를 두번 하는 것이 효과적이다라는 것을 찾아내었기 때문입니다.\n",
    "\n",
    "    아래보시면 파라미터 수와 실수연산은 더 적은데 같은 효과를 볼 수 있는데다가,\n",
    "    오히려 non-linearity를 두 번 적용한 더 좋은 결과가 나온다는 것을 보실 수 있습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide76.PNG?raw=true)\n",
    "\n",
    "    빨간색 conv layer의 맨 왼쪽 한 칸이 파란색 박스의 3x3 conv layer의 receptive field를 담고 있겠죠?\n",
    "    다음칸을 보면 이 가운데 3x3을 담고 있겠구요, stride가 1일 때요,\n",
    "    그렇기 때문에 3x3 conv 두 번이면 5x5 conv가 가지고 있는 receptive field와 같다고 할 수 있습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_044.png?raw=true)\n",
    "\n",
    "    두번째 룰은 plooing을 할때, feature map을 반으로 줄이고 채널(필터) 수를 두배로 키워줍니다.\n",
    "    한정 된 computing resource에서 같은 실수 연산 cost를 유지할 때,\n",
    "    메모리는 줄이고 kernel사용 수는 두배로 늘릴 수 있기 때문입니다.\n",
    "    (Memory=H*W*C , Params=c_in*c_out*k_h*k_w, Params=(k_h*k_w*k_z)*filters_num, FLOPs=(c_out*h*w)*(c_in*k_h*k_w)\n",
    "\n",
    "    이 룰은 아직도 많은 cnn 아키텍쳐들이 따르고 있는 디자인 룰 중에 하나입니다.\n",
    "\n",
    "***\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 VGGNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide77.PNG?raw=true)\n",
    "\n",
    "    에러 그래프를 보시면 16레이어까지는 깊게 쌓을 수록 에러가 낮아지는 것을 볼 수 있는데,\n",
    "    더 깊게 쌓으면 에러가 차라리 높아지는 것을 볼 수 있습니다.\n",
    "    깊어질수록 많아지는 많은 연산량이 필요하고 weight paramiter들을 optimize를 하는 것이 어려웠기 때문이데요.\n",
    "    어떠한 테크닉을 통해 극복했는지 잠시 후 알아보도록 하고, 먼저 구글넷을 살펴보겠습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: Inception module\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide92.PNG?raw=true)\n",
    "\n",
    "    14년도 Imagenet challange(ILSVRC) 1위를 한 GooLeNet입니다.\n",
    "    GooLeNet에서 중간에 L자가 대문자인 이유는 얀르쿤교수팀이 개발한 Lenet을 리스펙트하는 의미로 하였구요.\n",
    "    네트워크 아키텍쳐가 조금 복잡해보이는데요, 가장 눈에 띄는점은 뭐 이렇게 묶음이 있구요,\n",
    "    중간중간 곁가지 처럼 나온게 있네요.\n",
    "\n",
    "    이 묶음이랑 곁가지를 제외하고 본다면 일반적인 CNN구조와 유사하게 매우 단순한 구조로 가지고 있습니다.\n",
    "\n",
    "    우선 옆으로 나온 곁가지에 대해 설명드리자면,\n",
    "    끝에서 나온 loss는 vanishing gardient문제로 인해서 초반 layer들에게 영향을 줄 수 없으니까,\n",
    "    조금이라도 보완하고자 중간중간 loss도 뽑아서 역전파를 시키자는 trick입니다.\n",
    "\n",
    "    15년도에 batch normalizaion이라는 학습 방법이 나온 뒤는 더이상 사용하지 않는 trick이구요,\n",
    "    이 묶음에 대해서 자세히 알아보자면,\n",
    "\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: Inception module\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide93.PNG?raw=true)\n",
    "\n",
    "    이 묶음을 확대하면 이렇습니다. 이 묶음의 inception module이라고 합니다.\n",
    "    영화 인셉션에서 \"우리는 좀더 깊이 들어가야해.\"라는 대사가 나옵니다. 영화에선 꿈의 심연을 뜻하는거겠죠?\n",
    "    딥러닝에서도 좀 더 깊이 네트워크를 쌓고자하는 바램에서 inception이란 이름을 따왔습니다.\n",
    "\n",
    "    inception module은 parallel한 병렬구조를 가지고 있습니다.\n",
    "    1x1 conv를 빼고보자면, 그냥 input도 넘겨주고,\n",
    "    3x3 conv한 것도 넘겨주고, 5x5 conv한것도 넘겨주고, 3x3 pooling 한것도 넘겨주네요,\n",
    "    한가지 input에 대해서 동시에 다양한 방면으로 본다는 의미에서 좋아 보입니다.\n",
    "\n",
    "    그리고 마지막에 합치는 것을 볼 수 있네요\n",
    "    여기서 합치는 것을 concat, stack 이라고 부르는데 값을 합치는 것이 아닌,\n",
    "    단순히 채널들을 순서대로 쌓는다는 의미입니다.\n",
    "\n",
    "    이렇게 합치다보면 너무 channel이 두꺼워지니까 1x1 conv를 통해 채널을 줄이는 연산입니다.\n",
    "    넓이와 높이를 줄이는데 pooling이 있듯이 channel을 줄이는데는 1x1 conv를 사용할 수 있으며\n",
    "    이 레이어를 병목처럼 줄인다고하여 bottleneck layer라고 합니다.\n",
    "\n",
    "    좀 더 쉽게 설명하자면 식빵이 들어오면,\n",
    "    이 식빵을 4개로 잘라서 다양한 크기의 돋보기로 4명의 사람이 살펴보고 특이한 것을 마킹을하고\n",
    "    다시 식빵을 합치는 겁니다.\n",
    "    근데 식빵이 이 과정을 할때마다 두꺼워져서 양옆에서 손으로 한번씩 눌러줘서 원래크기 비슷하게 맞춰주는거죠.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: batch normalization\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/covariate_shift.jpg?raw=true)\n",
    "\n",
    "    그리고 15년도에 batch normalization이 나온 후 부터는 곁가지 트릭은 쓰지 않는다고 말씀드렸습니다.\n",
    "    batch norm/bn이라고 부르는 이 방법은,\n",
    "    학습시에 현재 layer의 입력은 모든 이전 layer의 파라미터의 변화에 영향을 받게 되며,\n",
    "    망이 깊어짐에 따라 이전 layer에서의 작은 파라미터 변화가 증폭되어\n",
    "    뒷단에 큰 영향을 끼치게 되는 문제가 발생할 수 있습니다. 마치 나비효과처럼요.\n",
    "    이것을 “Covariate Shift”라고 합니다.\n",
    "    그래서 우리는 중간중간 이를 바로잡아줄 방법이 필요한데,\n",
    "    이게 바로 batch norm입니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: batch normalization\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide80.PNG?raw=true)\n",
    "\n",
    "    batch normalization의 원리는 간단합니다.\n",
    "    학습은 mini-batch단위로 진행하기 때문에\n",
    "    mini-batch의 평균과 분산을 구해서, 데이터를 -1~1사이로 normalization을 시켜줍니다.\n",
    "\n",
    "    우리는 normalization에 scale값과 shift를 추가하여 이 변수도 같이 학습을 통해 정하게 하여,\n",
    "    전체 dataset을 normalization을 해주는 factor를 찾게하여 단순하게 정규화만을 할 때 보다 훨씬 강력하게 만듭니다.\n",
    "\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: batch normalization\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide81.PNG?raw=true)\n",
    "\n",
    "    googLe net의 업그레이드 버전이 inception-v2부터는 batch norm을 적용하는데,\n",
    "    보시는 것처럼 같은 네트워크에서 bn이 없을때와 bn이 있을때\n",
    "    얼마나 잘 network 학습하는지, 정확도가 나오는지 증명하고 있습니다.\n",
    "    (학습 진도율을 키운 BN-x30의 경우는 기존 Inception 보다 6배 빠르게 학습되며 더 높은 정확도에 도달할 수 있었습니다.)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 GooLeNet: batch normalization\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/lecture_1_ranjay.pdf_page_10.png?raw=true)\n",
    "\n",
    "    batch norm과 다양한 딥러닝 학습 테크닉의 발견으로 우리는 더 깊게 network를 쌓을 수 있습니다.\n",
    "    15년도 이후 논문들의 layer 수를 보면 100개를 훌쩍 넘는 것을 볼 수 있습니다.\n",
    "    정확도도 눈에 띄게 향상됬구요.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_060.png?raw=true)\n",
    "\n",
    "    그런데 오른쪽 그래플 한 번 볼까요?\n",
    "    보이는 것처럼 Test dataset에 대한 에러는 56개를 쌓은 layer의 에러가 더 높네요.\n",
    "    아마도 레이어가 깊다보니 학습데이터 셋을 외워버리는 overfitting일 일어난 것 같습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_061.png?raw=true)\n",
    "\n",
    "    그런데 training error를 보니까, training dataset에 대한 error도 높네요?\n",
    "    사실은 overfitting이 아닌 학습이 잘 되지 않은 underfitting이 일어나는 겁니다\n",
    "    아까 위에서 언급했던 VGG에서 레이어를 깊게 쌓을 수록 error가 올라가는 상황이죠?\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_063.png?raw=true)\n",
    "\n",
    "    깊은 모델은 얕은 모델보다 더 성능이 잘 나와야합니다.\n",
    "    예를들어 20개의 layer를 가진 모델 뒤에 아웃풋을 그대로 통과시키는\n",
    "    36개 레이어를 붙인다고해도 성능이 떨어질 이유가 없기 때문이죠.\n",
    "\n",
    "    여기서 \"깊은 네트워크가 가장 낮은 loss를 찾는 weight paramiter를 optimization를 하는 것이\n",
    "    잘 안되는 게 아닌가?\"라는 추측을 하게됩니다.\n",
    "\n",
    "    그래서 간단하게 \"20개의 레이어를 결과를 그대로 출력하면서\n",
    "    뒤에 36개는 조금만 추가적으로 일하면 성능이 잘 나올것이다\"라는 생각에서\n",
    "    앞에 레이어의 정보를 유지하면서 추가 정보를 붙이는 identity function을 설계하게 됩니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide82.PNG?raw=true)\n",
    "\n",
    "    이 그림은 resnet의 residual block(나머지블록, 리지듀얼)이라고 부르는 module인데요,\n",
    "    아래 보이는 residual connection, shortcut, skip connection이라고도 부르는데요,\n",
    "    이게 앞에서 넘겨준 정보를 그대로 유지해주는 identity function입니다.\n",
    "\n",
    "    그리고 resnet은 이 residual block을 반복하면서 네트워크를 만듭니다.\n",
    "    여기서 더하는 것은 inception module처럼 concat를 하는 것은 아니고 두 레이어를 출력 값을 더하는 겁니다.\n",
    "    (역전파를 할 때 더하기 연산은 값을 그대로 복사하기 때문에 이전 feature 공유의 indentity를 유지할 수 있습니다.)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide84.PNG?raw=true)\n",
    "\n",
    "    이렇게 residual block을 쌓아서 18개부터 152개 까지의 다양한 resnet 아키텍쳐를 만듭니다.\n",
    "\n",
    "    보시면 inception구조처럼 bottleneck layer,\n",
    "    1x1 conv를 통해서 채널 수를 줄여주고 있는 것을 보실 수 있습니다.\n",
    "\n",
    "    이 방법을 통해서 깊게 쌓으면서도 연산은 VGG-16(13.6)보다 적게 사용하고 있습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 ResNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/498_FA2019_lecture08.pdf_page_079.png?raw=true)\n",
    "\n",
    "    이 모델 아키텍쳐는 기대한대로 깊게 쌓을수록 네트워크 성능이 좋아진다는 것을 증명하였고,\n",
    "    resnet을 backbone으로 한 5개의 challage 분야에서 1위를 달성했습니다.\n",
    "    매우 심플한 network design에 좋은 성능을 내어 아직까지도 많이 사랑받는 network이며,\n",
    "    전문가들도 어떠한 문제를 해결하려고 할때 pilot network로\n",
    "    resnet을 backbone으로 실험해보길 추천하고 있습니다.\n",
    "\n",
    "    그럼 실습을 통해 Resnet구현을 해보겠습니다.\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act='relu', epoch=300, exp_name='exp1_lr', l2=1e-05, lr=0.001, model='Resnet', optim='SGD', test_batch_size=64, train_batch_size=256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 8.00 GiB total capacity; 5.94 GiB already allocated; 169.75 MiB free; 315.58 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-29b915f96689>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[1;31m#torchsummary.summary(Resnet().cuda(), (3, 32, 32))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 93\u001B[1;33m \u001B[0msetting\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeepcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     94\u001B[0m \u001B[0mplot_loss_variation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[0mplot_acc_variation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-1-ab8b5c6380c8>\u001B[0m in \u001B[0;36mexperiment\u001B[1;34m(partition, args)\u001B[0m\n\u001B[0;32m    218\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# loop over the dataset multiple times\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m         \u001B[0mts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m         \u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    221\u001B[0m         \u001B[0mval_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m         \u001B[0mte\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-1-ab8b5c6380c8>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(net, partition, optimizer, criterion, args)\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 122\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    124\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-29b915f96689>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[1;31m#x = self.maxpool(x)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-29b915f96689>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbn3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresidual\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mrelu\u001B[1;34m(input, inplace)\u001B[0m\n\u001B[0;32m    912\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    913\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 914\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    915\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 8.00 GiB total capacity; 5.94 GiB already allocated; 169.75 MiB free; 315.58 MiB cached)"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False) # 1x1\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) # 3x3\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False) # 1x1\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != 4 * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, 4 * planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(4 * planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(residual) # identity function\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# resnet-50\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)    # for cifar-10\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)   # for cifar-10\n",
    "        self.layer1 = self.residual_block(64, 3, stride=1)\n",
    "        self.layer2 = self.residual_block(128, 4, stride=2)\n",
    "        self.layer3 = self.residual_block(256, 6, stride=2)\n",
    "        self.layer4 = self.residual_block(512, 3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "\n",
    "    def residual_block(self, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inplanes , planes, stride))\n",
    "        self.inplanes = planes * 4\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr\"\n",
    "#models = ['CNN', 'Resnet']\n",
    "args.model = 'Resnet'\n",
    "args.act = 'relu'\n",
    "args.l2 = 0.00001\n",
    "args.optim = 'SGD'  # 'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 1e-3\n",
    "args.epoch = 300\n",
    "\n",
    "args.train_batch_size = 256\n",
    "args.test_batch_size = 64\n",
    "\n",
    "\n",
    "#torchsummary.summary(Resnet().cuda(), (3, 32, 32))\n",
    "print(args)\n",
    "setting, result = experiment(partition, deepcopy(args))\n",
    "plot_loss_variation(result)\n",
    "plot_acc_variation(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.5 DenseNet\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide86.PNG?raw=true)\n",
    "\n",
    "    다음 살펴볼 Network는 DenseNet입니다. 이전 정보를 좀 Dense하게 넘겨준다고해서 DenseNet이구요.\n",
    "    Resnet을 identity function과 conv연산한 마지막 output을 더한다는 점에서\n",
    "    이후의 레이어들로 온전히 흘러가는 것을 방해할 수 있다는 약점이 있었는데요,\n",
    "\n",
    "    DenseNet에서는 이런 connection을 더욱 강화해서 바로 다음레이어 뿐만아니라 앞에 레이어 들에게\n",
    "    전달을하면서, 더하기 연산이 아닌 concat으로 채널을 쌓습니다.\n",
    "    예를 들어 input이 6이면 다음은 6+4 그다음에는 6+4+4의 input 정보가 전달되는 것이죠.\n",
    "\n",
    "    이 Dense module을 반복하다보면 당연히, 채널이 너무 두꺼워 지겠죠?\n",
    "    이를 줄여주기 위해 중간에 Transition layer를 둬서 중간중간 한번씩 줄여줍니다.\n",
    "    w,h는 반으로 줄여주고 c는 compression factor를 받아줄여주는데 보통 0.5로 해서 채널도 반으로 줄입니다.\n",
    "\n",
    "    그럼 DenseNet을 코드로 구현해 보겠습니다.\n",
    "\n",
    "    (DenseNet-BC = bottleneck layer + transition layer,\n",
    "    growth_rate는 feature map channel을 얼마씩 더해 나갈지)\n",
    "\n",
    "    (growth_rate = 4\n",
    "    compression factor = 0.5\n",
    "    input = 6\n",
    "    [6 -> (6)+4 -> (6+4)+4 -> (6+4+4)+4 -> (6+4+4+4)+4 = 22(32x32x22)] DenseBlock x 3\n",
    "    -(transition)> (16x16x11) (16은 2x2풀링, 11은 1x1 factor 0.5)\n",
    "    마지막에 Nx8x8 -(global avg pooling)> Nx1x1 -(flatten)> FC)\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-1cc22d59d04e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mclass\u001B[0m \u001B[0mBottleneckBlock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0min_planes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_planes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdrop_rate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[1;31m# out_planes => growth_rate를 입력으로 받게 된다.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBottleneckBlock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0minter_planes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mout_planes\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m4\u001B[0m  \u001B[1;31m# hyper paraamiter : 4*growth_rate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, drop_rate=0.0):\n",
    "        # out_planes => growth_rate를 입력으로 받게 된다.\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        inter_planes = out_planes * 4  # hyper paraamiter : 4*growth_rate\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(inter_planes)\n",
    "        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.drop_rate > 0:\n",
    "            out = self.dropout (out)\n",
    "        out = self.conv2(self.relu(self.bn2(out)))\n",
    "        if self.drop_rate > 0:\n",
    "            out = self.dropout (out)\n",
    "        return torch.cat([x, out], 1)  # 입력으로 받은 x와 새로 만든 output을 합쳐서 내보낸다\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, growth_rate, block, drop_rate=0.0):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, drop_rate)\n",
    "\n",
    "    def _make_layer(self, block, in_planes, growth_rate, nb_layers, drop_rate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(in_planes + i * growth_rate, growth_rate, drop_rate))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class TransitionBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, drop_rate=0.0):\n",
    "        super(TransitionBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "        self.avg_pooling = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu(self.bn1(x)))\n",
    "        if self.drop_rate > 0:\n",
    "            out = self.dropout(out)\n",
    "        return self.avg_pooling(out)\n",
    "\n",
    "\n",
    "class Densenet(nn.Module):\n",
    "    def __init__(self, layers=121, num_classes=10, growth_rate=12, compression_factor=0.5, drop_rate=0.2):\n",
    "        super(Densenet, self).__init__()\n",
    "        num_of_blocks = 3\n",
    "        n = (layers - num_of_blocks - 1) / num_of_blocks  # n = layers-(conv,transit,linear)/ num_of_blocks\n",
    "        in_planes = 2 * growth_rate  # hyper param: first layer=2*growth_rate\n",
    "        n = n // 2  # except conv 1x1, the number of bottlenecks\n",
    "        block = BottleneckBlock\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)  # input:RGB -> output:growthR*2\n",
    "\n",
    "        # 1st block\n",
    "        self.block1 = DenseBlock(n, in_planes, growth_rate, block, drop_rate)\n",
    "        in_planes = int(in_planes + n * growth_rate)\n",
    "        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes * compression_factor)), drop_rate=drop_rate)\n",
    "        in_planes = int(math.floor(in_planes * compression_factor))\n",
    "\n",
    "        # 2nd block\n",
    "        self.block2 = DenseBlock(n, in_planes, growth_rate, block, drop_rate)\n",
    "        in_planes = int(in_planes + n * growth_rate)\n",
    "        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes * compression_factor)), drop_rate=drop_rate)\n",
    "        in_planes = int(math.floor(in_planes * compression_factor))\n",
    "\n",
    "        # 3rd block\n",
    "        self.block3 = DenseBlock(n, in_planes, growth_rate, block, drop_rate)\n",
    "        in_planes = int(in_planes + n * growth_rate)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.ada_avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.fc = nn.Linear(in_planes, num_classes)  # 마지막에 ave_pool 후에 1x1 size의 결과만 남음.\n",
    "\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        # init module\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)  #\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : 32*32\n",
    "        out = self.conv1(x)  # 32*32\n",
    "        out = self.block1(out)  # 32*32\n",
    "        out = self.trans1(out)  # 16*16\n",
    "        out = self.block2(out)  # 16*16\n",
    "        out = self.trans2(out)  # 8*8\n",
    "        out = self.block3(out)  # 8*8\n",
    "        out = self.relu(self.bn1(out))  # 8*8\n",
    "        out = self.ada_avg_pooling(out)  # 1*1\n",
    "        out = out.view(-1, self.in_planes)  # flatten\n",
    "        return self.fc(out)\n",
    "\n",
    "# layers,num_classes <- cifar '10' ,growth_rate=12,compression_factor=0.5,bottleneck=True,drop_rate=0.0\n",
    "\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr\"\n",
    "#models = ['CNN', 'Resnet', 'Densenet']\n",
    "args.model = 'Densenet'\n",
    "args.act = 'relu'\n",
    "args.l2 = 0.00001\n",
    "args.optim = 'SGD'  # 'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 1e-3\n",
    "args.epoch = 300\n",
    "\n",
    "args.train_batch_size = 128\n",
    "args.test_batch_size = 64\n",
    "\n",
    "#torchsummary.summary(Densenet().cuda(), (3, 32, 32))\n",
    "print(args)\n",
    "setting, result = experiment(partition, deepcopy(args))\n",
    "plot_loss_variation(result)\n",
    "plot_acc_variation(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.6 Sqeeze-and-excitation networks\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide87.PNG?raw=true)\n",
    "\n",
    "    위에서 본 network들은 feature간의 spatial correlation을 강화하는 네트워크들 인데요,\n",
    "    SENet은 다른 측면으로, channel 간의 relationship을 연구하였습니다.\n",
    "\n",
    "    squeeze를 통해서 channel의 1x1 Global Information Embedding을 한 후,\n",
    "    채널 간의 중요성을 알아내기 위해 Excitation(자극), fc를 통한 채널의 attention을 진행합니다.\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/excitation.png?raw=true)\n",
    "\n",
    "    학습을 통해 w값을 변경하면서 유익한 feature를 선택적으로 강조하고\n",
    "    덜 유용한 feature를 억제하는 feature recalibration을 할 수 있습니다.\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/SENet_Fig_3.png?raw=true)\n",
    "\n",
    "    또한, SE block은 residual network에도 다양한 네트워크에 직접 사용될 수 있습니다.\n",
    "    original ResNet-50에 비해, 계산량이 0.26%의 상대적 소폭 증가합니다.\n",
    "\n",
    "    그럼 Resnet에 SE모듈을 적용해보는 코드를 짜보도록 하시죠.\n",
    "\n",
    "\n",
    "    (Squeeze(짜내다): Global Information Embedding (Global pooling per channel) -\n",
    "    Excitation(자극): Adaptive Recalibration (self-attetion on chennel through fc))\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act='relu', epoch=300, exp_name='exp1_lr', l2=1e-05, lr=0.001, model='SE_Resnet', optim='SGD', test_batch_size=64, train_batch_size=256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.20 GiB already allocated; 23.75 MiB free; 139.80 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-52c0ffd23942>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[1;31m#torchsummary.summary(Resnet().cuda(), (3, 32, 32))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m \u001B[0msetting\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeepcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m \u001B[0mplot_loss_variation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[0mplot_acc_variation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-1-ab8b5c6380c8>\u001B[0m in \u001B[0;36mexperiment\u001B[1;34m(partition, args)\u001B[0m\n\u001B[0;32m    218\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# loop over the dataset multiple times\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m         \u001B[0mts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m         \u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    221\u001B[0m         \u001B[0mval_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpartition\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m         \u001B[0mte\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-1-ab8b5c6380c8>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(net, partition, optimizer, criterion, args)\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 122\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    124\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-52c0ffd23942>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     80\u001B[0m         \u001B[1;31m#x = self.maxpool(x)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 82\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     83\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer4\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-52c0ffd23942>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbn2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbn3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresidual\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    539\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 541\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-52c0ffd23942>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mavg_pool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m)\u001B[0m     \u001B[1;31m# [b,c,1,1] -> [b,c]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m     \u001B[1;31m# [b,c] -> [b,c,1,1]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand_as\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m              \u001B[1;31m# [b,c,1,1] -> [b,c,width,height]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.20 GiB already allocated; 23.75 MiB free; 139.80 MiB cached)"
     ]
    }
   ],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction):\n",
    "        super(SELayer, self).__init__()\n",
    "        # squeeze\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # excitation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)     # [b,c,1,1] -> [b,c]\n",
    "        y = self.fc(y).view(b, c, 1, 1)     # [b,c] -> [b,c,1,1]\n",
    "        y = x * y.expand_as(x)              # [b,c,1,1] -> [b,c,width,height]\n",
    "        return y\n",
    "\n",
    "class SE_Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1, reduction=16):\n",
    "        super(SE_Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, 4*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(4*planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != 4 * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, 4 * planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(4 * planes)\n",
    "            )\n",
    "        self.se = SELayer(planes * 4, reduction)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# resnet-50\n",
    "class SE_Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SE_Resnet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)    # for cifar-10\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)   # for cifar-10\n",
    "        self.layer1 = self.residual_block(64, 3, stride=1)\n",
    "        self.layer2 = self.residual_block(128, 4, stride=2)\n",
    "        self.layer3 = self.residual_block(256, 6, stride=2)\n",
    "        self.layer4 = self.residual_block(512, 3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "\n",
    "    def residual_block(self, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(SE_Bottleneck(self.inplanes , planes, stride))\n",
    "        self.inplanes = planes * 4\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(SE_Bottleneck(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr\"\n",
    "#models = ['CNN', 'Resnet', 'SE_Resnet']\n",
    "args.model = 'SE_Resnet'\n",
    "args.act = 'relu'\n",
    "args.l2 = 0.00001\n",
    "args.optim = 'SGD'  # 'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 1e-3\n",
    "args.epoch = 300\n",
    "\n",
    "args.train_batch_size = 256\n",
    "args.test_batch_size = 64\n",
    "\n",
    "\n",
    "#torchsummary.summary(Resnet().cuda(), (3, 32, 32))\n",
    "print(args)\n",
    "setting, result = experiment(partition, deepcopy(args))\n",
    "plot_loss_variation(result)\n",
    "plot_acc_variation(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.7 State-of-the-art\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/pt/Slide89.PNG?raw=true)\n",
    "![pt](https://github.com/tiktakdad/dl4cv/blob/master/images/sota_top1.png?raw=true)\n",
    "\n",
    "    여기까지 굵직굵직한 CNN backbone들을 살펴봤습니다.\n",
    "    그럼 마지막장으로 SOTA network를 소개하면서 앞으로의 CV for DL에 대한 방향성을 예측해보면서 마무리 할까합니다.\n",
    "\n",
    "    [첫번째는 NAS 입니다.]\n",
    "    Network Architecture Search 말 그대로\n",
    "    네트웤을 우리가 설계하지말고 딥러닝한테 이것도 하게하자는 AutoML분야 Network입니다.\n",
    "    어차피 Layer의 구조, 형태, 수 등은 실험에 의존되는 hyper parameter이기 때문입니다.\n",
    "\n",
    "    NAS의 기본적인 아이디어는 단순합니다.\n",
    "    RNN으로 구성된 controller를 이용해 child network를 만들고,\n",
    "    특정 데이터셋 (ex. CIFAR-10)에 대해 validation accuracy가 수렴할 때까지 child network를 학습시킵니다.\n",
    "    Controller는 필터의 개수와 크기, stride 등 하나의 convolutional layer를 표현하는 hyperparameter들을 결정합니다.\n",
    "\n",
    "    RNN과 강화학습으로 으로 구성된 controller를 이용해 conv, subsampling cell 조합으로 child network를 만들어가는 NASNet과\n",
    "    시드 모델 집합에서 적자생존을 방법으로 레이어 집합을 선택하는 진화 알고리즘(Evolutionary Algorithm) 기반 AmeobaNet이 있습니다.\n",
    "\n",
    "    [두번째는 EfficientNet 입니다.]\n",
    "    (rethinking Model Scaling for Convolutional Neural Networks)\n",
    "    모델의 크기를 키워주는 방법으로는 대표적으로\n",
    "    filter의 개수를(channel의 개수를) 늘리는 width scaling과\n",
    "    layer의 개수를 늘리는 depth scaling과\n",
    "    input image의 해상도를 높이는 resolution scaling 이 자주 사용됩니다.\n",
    "    하지만 기존 방식들에서는 위의 3가지 scaling을 동시에 고려하는 경우가 거의 없었습니다.\n",
    "    grid search 를 수행하여 3개의 값을 모두 바꾸는 최적의 compound scaling을 구합니다.\n",
    "    알파(depth)은 1.2, 베타(width)은 1.1, 감마(resolution)은 1.15를 사용하여 scale 변화를 진행하여 실험하였습니다.\n",
    "\n",
    "    [세번째는 GPipe입니다.]\n",
    "    (Efficient Training of Giant Neural Networks using Pipeline Parallelism)\n",
    "    거대한 Neural Networks에 대한 학습 방법론으로 Network가 아닌 Library입니다.\n",
    "    Network이 거대해지면 한 디바이스에 올릴 수 없으므로,\n",
    "    micro batch 단위로 모델을 N개의 sequentail layer로 나눈 layer들을 병렬 학습 시키는 구조입니다.\n",
    "\n",
    "    [마지막은 Vision Transformer, ViT입니다.]\n",
    "    (An Image is Worth 16X16 Words: Transformers for Image Recognition at Scale)\n",
    "    언어모델에서 사용하는 Transformer구조를 이용하여 cnn을 사용하지 않고 이미지 인식을 하는 network인데,\n",
    "    놀라울만한 성능을 보여주었기 때문에 눈여겨봐야 할 network입니다.\n",
    "\n",
    "    2d 이미지기 때문에 16x16 패치를 나눠서,\n",
    "    16x16 -(flatten, cnn/hybrid)> linear projection(MLP) -> 1d array -> transformer(attention) -> clssification\n",
    "    하는 구조입니다.\n",
    "    transformer는 translation invariance 및 locality와 같은 CNN 고유의 inductive bias가 없기 때문에\n",
    "    불충분한 양의 data에 대해 학습할 때 일반화가 잘 되지 않는다.\n",
    "    그러나 large-scale dataset(14M-300M Images)에서 모델을 학습하면, CNN보다 좋은 성능을 보입니다.\n",
    "    (hybrid모델은 CNN과 마찬가지로 neiborhood의 정보를 가져오는 inductive bias 영향으로 보임)\n",
    "\n",
    "\n",
    "***\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}